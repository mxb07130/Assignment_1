{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1- Mathematical Part Solution is provided in Document, the below code is just for reference for Q1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "a = np.array([0.4005,0.2148,0.3457,0.2652,0.0789,0.4548])\n",
    "b = np.array([0.5306,0.3854,0.3156,0.1875,0.4139,0.3022])\n",
    "\n",
    "point = ['P1','P2','P3','P4','P5','P6']\n",
    "data = pd.DataFrame({'Point':point, 'x cordinate':a, 'y cordinate':b})\n",
    "data = data.set_index('Point')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.DataFrame(squareform(np.round(pdist(data[['x cordinate', 'y cordinate']]),4), 'euclidean'), columns=data.index.values, index=data.index.values)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02309c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4)) \n",
    "plt.title(\"Dendrogram with Single inkage\")  \n",
    "dend = shc.dendrogram(shc.linkage(data[['x cordinate', 'y cordinate']], method='single'), labels=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbbc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4)) \n",
    "plt.title(\"Dendrogram with Complete inkage\")  \n",
    "dend = shc.dendrogram(shc.linkage(data[['x cordinate', 'y cordinate']], method='complete'), labels=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4)) \n",
    "plt.title(\"Dendrogram with Average inkage\")  \n",
    "dend = shc.dendrogram(shc.linkage(data[['x cordinate', 'y cordinate']], method='average'), labels=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db364614",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Use CC_GENERAL.csv given in the folder and apply:\n",
    "# a) Preprocess the data by removing the categorical column and filling the missing values.\n",
    "# b) Apply StandardScaler() and normalize() functions to scale and normalize raw input data.\n",
    "# c) Use PCA with K=2 to reduce the input dimensions to two features.\n",
    "# d) Apply Agglomerative Clustering with k=2,3,4 and 5 on reduced features and visualize\n",
    "# result for each k value using scatter plot.\n",
    "# e) Evaluate different variations using Silhouette Scores and Visualize results with a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries here for assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('CC GENERAL.csv')\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a87eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.drop(['CUST_ID'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c23941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7eb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(dataframe.mean(), inplace=True)\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().style.background_gradient(cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec36ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x)\n",
    "X_scaled_array = scaler.transform(x)\n",
    "X_scaled_df = pd.DataFrame(X_scaled_array, columns = x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization is the process of scaling individual samples to have unit norm. \n",
    "#This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples.\n",
    "X_normalized = preprocessing.normalize(X_scaled_df)\n",
    "# Converting the numpy array into a pandas DataFrame\n",
    "X_normalized = pd.DataFrame(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=2)\n",
    "principalComponents = pca2.fit_transform(X_normalized)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['P1', 'P2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, df[['TENURE']]], axis = 1)\n",
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(finalDf['P1'],finalDf['P2'],c=finalDf['TENURE'],cmap='prism', s =5)\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac2 = AgglomerativeClustering(n_clusters = 2)\n",
    " \n",
    "# Visualizing the clustering\n",
    "plt.figure(figsize =(6, 6))\n",
    "plt.scatter(principalDf['P1'], principalDf['P2'],\n",
    "           c = ac2.fit_predict(principalDf), cmap ='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac3 = AgglomerativeClustering(n_clusters = 3)\n",
    " \n",
    "# Visualizing the clustering\n",
    "plt.figure(figsize =(6, 6))\n",
    "plt.scatter(principalDf['P1'], principalDf['P2'],\n",
    "           c = ac3.fit_predict(principalDf), cmap ='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac4 = AgglomerativeClustering(n_clusters = 4)\n",
    " \n",
    "# Visualizing the clustering\n",
    "plt.figure(figsize =(6, 6))\n",
    "plt.scatter(principalDf['P1'], principalDf['P2'],\n",
    "           c = ac4.fit_predict(principalDf), cmap ='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac5 = AgglomerativeClustering(n_clusters = 5)\n",
    " \n",
    "# Visualizing the clustering\n",
    "plt.figure(figsize =(6, 6))\n",
    "plt.scatter(principalDf['P1'], principalDf['P2'],\n",
    "           c = ac5.fit_predict(principalDf), cmap ='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be012aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [2, 3, 4, 5]\n",
    " \n",
    "# Appending the silhouette scores of the different models to the list\n",
    "silhouette_scores = []\n",
    "silhouette_scores.append(\n",
    "        silhouette_score(principalDf, ac2.fit_predict(principalDf)))\n",
    "silhouette_scores.append(\n",
    "        silhouette_score(principalDf, ac3.fit_predict(principalDf)))\n",
    "silhouette_scores.append(\n",
    "        silhouette_score(principalDf, ac4.fit_predict(principalDf)))\n",
    "silhouette_scores.append(\n",
    "        silhouette_score(principalDf, ac5.fit_predict(principalDf)))\n",
    "\n",
    " \n",
    "# Plotting a bar graph to compare the results\n",
    "plt.bar(k, silhouette_scores)\n",
    "plt.xlabel('Number of clusters', fontsize = 20)\n",
    "plt.ylabel('S(i)', fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
